{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arXiv Network",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJu0tacBRYKx"
      },
      "source": [
        "#Necessary Libraries\n",
        "import xml.etree.ElementTree as ET\n",
        "from urllib.parse import urlencode\n",
        "from urllib.request import urlopen\n",
        "from urllib.error import HTTPError\n",
        "import ssl\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1VPuMYWbioU"
      },
      "source": [
        "#All subcategories under Computer Science on arXiv\n",
        "cs_master = {\"cs.AI\":\"Artificial Intelligence\",\n",
        "\"cs.AR\":\"Hardware Architecture\",\n",
        "\"cs.CC\":\"Computational Complexity\",\n",
        "\"cs.CE\":\"Computational Engineering, Finance, and Science\",\n",
        "\"cs.CG\":\"Computational Geometry\",\n",
        "\"cs.CL\":\"Computation and Language\",\n",
        "\"cs.CR\":\"Cryptography and Security\",\n",
        "\"cs.CV\":\"Computer Vision and Pattern Recognition\",\n",
        "\"cs.CY\":\"Computers and Society\",\n",
        "\"cs.DB\":\"Databases\",\n",
        "\"cs.DC\":\"Distributed, Parallel, and Cluster Computing\",\n",
        "\"cs.DL\":\"Digital Libraries\",\n",
        "\"cs.DM\":\"Discrete Mathematics\",\n",
        "\"cs.DS\":\"Data Structures and Algorithms\",\n",
        "\"cs.ET\":\"Emerging Technologies\",\n",
        "\"cs.FL\":\"Formal Languages and Automata Theory\",\n",
        "\"cs.GL\":\"General Literature\",\n",
        "\"cs.GR\":\"Graphics\",\n",
        "\"cs.GT\":\"Computer Science and Game Theory\",\n",
        "\"cs.HC\":\"Human-Computer Interaction\",\n",
        "\"cs.IR\":\"Information Retrieval\",\n",
        "\"cs.IT\":\"Information Theory\",\n",
        "\"cs.LG\":\"Learning\",\n",
        "\"cs.LO\":\"Logic in Computer Science\",\n",
        "\"cs.MA\":\"Multiagent Systems\",\n",
        "\"cs.MM\":\"Multimedia\",\n",
        "\"cs.MS\":\"Mathematical Software\",\n",
        "\"cs.NA\":\"Numerical Analysis\",\n",
        "\"cs.NE\":\"Neural and Evolutionary Computing\",\n",
        "\"cs.NI\":\"Networking and Internet Architecture\",\n",
        "\"cs.OH\":\"Other Computer Science\",\n",
        "\"cs.OS\":\"Operating Systems\",\n",
        "\"cs.PF\":\"Performance\",\n",
        "\"cs.PL\":\"Programming Languages\",\n",
        "\"cs.RO\":\"Robotics\",\n",
        "\"cs.SC\":\"Symbolic Computation\",\n",
        "\"cs.SD\":\"Sound\",\n",
        "\"cs.SE\":\"Software Engineering\",\n",
        "\"cs.SI\":\"Social and Information Networks\",\n",
        "\"cs.SY\":\"Systems and Control\"}\n",
        "\n",
        "cat = list(cs_master.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbjXlwtBSKwM"
      },
      "source": [
        "#Function to generate an edge list for the input of list of authors\n",
        "def gen_edge_list(sub_list):\n",
        "    list_nodes = []\n",
        "    n = len(sub_list)\n",
        "    \n",
        "    if n==1:\n",
        "        list_nodes.append(tuple(sub_list))\n",
        "    \n",
        "    else:\n",
        "        for i in range(n):\n",
        "            for j in range(i+1,n):\n",
        "                list_nodes.append((sub_list[i],sub_list[j]))\n",
        "    return list_nodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yca-G_MSLUd"
      },
      "source": [
        "#Main function doing the scraping and returning the edge list of the co-authorship network and the list of nodes\n",
        "def output(cat,**extra):\n",
        "    category = cs_master[cat]\n",
        "    \n",
        "    if(bool(extra)):\n",
        "        s = str(extra['start'])\n",
        "        url = 'http://export.arxiv.org/api/query?search_query=cat:' + cat + '&start=' + s + '&max_results=10000&sortBy=submittedDate&sortOrder=ascending'\n",
        "    \n",
        "    else:\n",
        "        url = 'http://export.arxiv.org/api/query?search_query=cat:' + cat + '&start=0&max_results=10000&sortBy=submittedDate&sortOrder=ascending'\n",
        "    \n",
        "    uh = urlopen(url)\n",
        "    data = uh.read()\n",
        "    tree = ET.fromstring(data)\n",
        "    total = int(tree.find('./{http://a9.com/-/spec/opensearch/1.1/}totalResults').text)   \n",
        "    \n",
        "    edge_list = []\n",
        "    authors_list = []\n",
        "    nodes_list = []\n",
        "    timeline = []\n",
        "    entries = tree.findall('.//{http://www.w3.org/2005/Atom}entry')\n",
        "    \n",
        "    for entry in entries:\n",
        "        \n",
        "        #date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
        "        #year = date.split('-')[0]\n",
        "        #timeline.append(int(year))\n",
        "        \n",
        "        authors = entry.findall('{http://www.w3.org/2005/Atom}author')\n",
        "        names = [author.find('{http://www.w3.org/2005/Atom}name').text for author in authors]\n",
        "        authors_list.append(names)\n",
        "    \n",
        "    for sub_list in authors_list:\n",
        "        for author in sub_list:\n",
        "            if(author not in authors_list):\n",
        "                nodes_list.append(author)\n",
        "    \n",
        "    all_edges = [gen_edge_list(sub_list) for sub_list in authors_list if len(sub_list) > 1]\n",
        "\n",
        "    for sub_list in all_edges:\n",
        "        for edge in sub_list:\n",
        "            edge_list.append(edge)\n",
        "    \n",
        "    if(total > 10000 and not bool(extra)):\n",
        "        n = int(total/10000) \n",
        "        for i in range(1,(n+1)):\n",
        "            (a,b) = output(cat, start = i*10000)\n",
        "            edge_list.extend(a)\n",
        "            nodes_list.extend(b)\n",
        "            #timeline.extend(c)        \n",
        "    \n",
        "    df_nodes = pd.DataFrame(nodes_list, columns = ['Node'])\n",
        "    df_nodes['Category'] = category\n",
        "    #years_range = [min(timeline),max(timeline)]\n",
        "         \n",
        "    return(edge_list,df_nodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZQk8WK-SPip",
        "outputId": "ffa5af50-a8af-4e3e-9f25-442def25a8aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(edge_list_ai,df_nodes_ai) = output(\"cs.AI\") \n",
        "\n",
        "print(\"Number of edges: \", len(edge_list_ai))\n",
        "print(\"Number of nodes: \", len(df_nodes_ai))\n",
        "#print(\"Records from: \", years_range_ai[0], \"to\", years_range_ai[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of edges:  206667\n",
            "Number of nodes:  26513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj80dbXoxcye"
      },
      "source": [
        "df_nodes_ai.to_csv(\"Nodes_list.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_UCk1jM3msv"
      },
      "source": [
        "#Creation of network from the edge list\n",
        "import networkx as nx\n",
        "G = nx.Graph()\n",
        "G.add_edges_from(edge_list_ai)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4toaCQZgMgAN"
      },
      "source": [
        "#Writing the network in a .gexf file to be used for analysis\n",
        "nx.write_gexf(G, \"test.gexf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT0AWU8xLI9m"
      },
      "source": [
        "edge_list_cs = []\n",
        "df_nodes_cs = pd.DataFrame(columns=['Node','Category'])\n",
        "years_range_cs = []\n",
        "\n",
        "for k in cs_master.keys():\n",
        "    (a,b,c) = output(k)\n",
        "    edge_list_cs.extend(a)\n",
        "    df_nodes_cs = df_nodes_cs.append(b)\n",
        "    years_range_cs.append(c)\n",
        "\n",
        "print(\"Number of edges: \", len(edge_list_cs))\n",
        "print(\"Number of nodes: \", len(df_nodes_cs))\n",
        "\n",
        "cats = list(cs_master.values())\n",
        "for i in range(len(cs_master)):\n",
        "  print(cats[i], \"--- Records from: \", years_range_cs[i][0], \"to\", years_range_cs[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
